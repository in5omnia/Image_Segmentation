{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_path = \"Abyssinian_1\"\n",
    "img_dir = \"Train/color/\"\n",
    "label_dir = \"Train/label/\"\n",
    "image = imageio.imread(f\"{img_dir}{img_path}.jpg\")\n",
    "mask = imageio.imread(f\"{label_dir}{img_path}.png\")\n",
    "mask = mask[:,:,0]\n",
    "\n",
    "# Define augmentation pipeline\n",
    "im_resize_padding = iaa.Sequential([\n",
    "    # Step 1: Pad to 1:1 aspect ratio (square) before resizing\n",
    "    iaa.PadToAspectRatio(\n",
    "        1.0,                     # Target aspect ratio (width/height)\n",
    "        position=\"center\",       # Center the image during padding\n",
    "        pad_mode=\"constant\",     # Pad with black (0) or use \"edge\"/\"reflect\"\n",
    "        pad_cval=0               # Value used for padding\n",
    "    ),\n",
    "    # Step 2: Resize to 512x512 (now safe, aspect ratio is 1:1)\n",
    "    iaa.Resize(\n",
    "        512\n",
    "    )\n",
    "])\n",
    "\n",
    "im_resize = iaa.Resize(512)\n",
    "\n",
    "# Define augmentation pipeline\n",
    "label_resize_padding = iaa.Sequential([\n",
    "    # Step 1: Pad to 1:1 aspect ratio (square) before resizing\n",
    "    iaa.PadToAspectRatio(\n",
    "        1.0,                     # Target aspect ratio (width/height)\n",
    "        position=\"center\",       # Center the image during padding\n",
    "        pad_mode=\"constant\",     # Pad with black (0) or use \"edge\"/\"reflect\"\n",
    "        pad_cval=0               # Value used for padding\n",
    "    ),\n",
    "    # Step 2: Resize to 512x512 (now safe, aspect ratio is 1:1)\n",
    "    iaa.Resize(\n",
    "        512,                     # Target size\n",
    "        interpolation=\"nearest\"   # For images (\"nearest\" for masks)\n",
    "    )\n",
    "])\n",
    "\n",
    "label_resize = iaa.Resize(512, interpolation=\"nearest\")\n",
    "\n",
    "\n",
    "\n",
    "# Apply to image and mask\n",
    "resized_image = aug.augment_image(image)\n",
    "resized_mask = aug_mask.augment_image(mask)  # Remove channel dim (back to H, W)\n",
    "\n",
    "resized_image_2 = resize.augment_image(image)\n",
    "\n",
    "plt.imshow(resized_image_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# Convert mask to SegmentationMapsOnImage object\n",
    "segmap = SegmentationMapsOnImage(mask, shape=image.shape)\n",
    "\n",
    "# Define augmentation with black padding\n",
    "aug = iaa.Affine(\n",
    "    rotate=(45, 315),\n",
    "    order=3,          # Image interpolation (cubic)\n",
    "    mode=\"constant\",  # Image padding mode\n",
    "    cval=0,           # Image padding value (black)\n",
    "    backend=\"cv2\"\n",
    ")\n",
    "\n",
    "# Apply augmentation\n",
    "augmented_image, augmented_segmap = aug(\n",
    "    image=image,\n",
    "    segmentation_maps=segmap\n",
    ")\n",
    "\n",
    "# Extract augmented mask\n",
    "augmented_mask = augmented_segmap.get_arr()\n",
    "\n",
    "plt.imshow(augmented_image)\n",
    "plt.show()\n",
    "plt.imshow(augmented_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "\n",
    "def random_square_crop_imgaug(image, mask, crop_biggest_square=False, random_state=None):\n",
    "    \"\"\"\n",
    "    Crops a square from the image and a corresponding label mask\n",
    "    using imgaug's built-in functions.\n",
    "\n",
    "    If crop_biggest_square is True, it will crop the biggest possible square\n",
    "    from the center of the image. Otherwise, it will crop a random square\n",
    "    with a side length of 2/3 of the smallest edge of the image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image (H, W, C).\n",
    "        mask (np.ndarray): The label mask (H, W).\n",
    "        crop_biggest_square (bool): Whether to crop the biggest square\n",
    "            from the center of the image. Defaults to False.\n",
    "        random_state (None or int or imgaug.random.RNG or numpy.random.RandomState, optional):\n",
    "            Random state to use for random operations. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the cropped image and the cropped mask.\n",
    "    \"\"\"\n",
    "\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState()  # Use numpy's RandomState by default\n",
    "    elif isinstance(random_state, int):\n",
    "        random_state = np.random.RandomState(random_state)\n",
    "    elif isinstance(random_state, ia.random.RNG):\n",
    "        pass  # Use the provided imgaug RNG directly\n",
    "    elif isinstance(random_state, np.random.RandomState):\n",
    "        pass  # Use the provided numpy RandomState directly\n",
    "    else:\n",
    "        raise ValueError(\"Invalid random_state.  Must be None, int, imgaug.random.RNG, or numpy.random.RandomState.\")\n",
    "\n",
    "\n",
    "    # Convert numpy RandomState to imgaug.random.RNG if needed\n",
    "    if isinstance(random_state, np.random.RandomState):\n",
    "        random_state = ia.random.RNG(random_state.randint(0, 10**6))\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    if crop_biggest_square:\n",
    "        cropper = iaa.CropToAspectRatio(1, \"center\")\n",
    "        cropped_image = cropper.augment_image(image)\n",
    "        cropped_mask = cropper.augment_image(mask)\n",
    "    else:\n",
    "        # Crop a random square with a side length of 2/3 of the smallest edge\n",
    "        min_side = min(height, width)\n",
    "        crop_size = int(min_side * (2/3))\n",
    "\n",
    "        # Determine maximum possible top-left corner coordinates for the crop\n",
    "        max_x = width - crop_size\n",
    "        max_y = height - crop_size\n",
    "\n",
    "        # Generate random top-left corner coordinates\n",
    "        x1 = random_state.randint(0, max_x + 1)\n",
    "        y1 = random_state.randint(0, max_y + 1)\n",
    "\n",
    "        # Create a bounding box object representing the crop\n",
    "        bbox = ia.BoundingBox(x1=x1, y1=y1, x2=x1 + crop_size, y2=y1 + crop_size)\n",
    "        bbs = ia.BoundingBoxesOnImage([bbox], shape=image.shape)\n",
    "\n",
    "        # Crop the image and mask based on the bounding box\n",
    "        cropper = iaa.CropToFixedSize(width=crop_size, height=crop_size) # Crop and resize to the crop size\n",
    "        cropped_image = cropper.augment_image(image[bbox.y1:bbox.y2, bbox.x1:bbox.x2])\n",
    "        cropped_mask = cropper.augment_image(mask[bbox.y1:bbox.y2, bbox.x1:bbox.x2])\n",
    "\n",
    "\n",
    "    return cropped_image, cropped_mask\n",
    "\n",
    "\n",
    "# Crop the image and mask using the imgaug function\n",
    "cropped_image, cropped_mask = random_square_crop_imgaug(image, mask, True)\n",
    "\n",
    "plt.imshow(cropped_image)\n",
    "plt.show()\n",
    "plt.imshow(cropped_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# Assuming 'image' is your input image array (H,W,C) \n",
    "# and 'label_mask' is your integer-label array (H,W)\n",
    "seg_map = SegmentationMapsOnImage(mask, shape=image.shape)\n",
    "\n",
    "# Define augmenters with CoarseDropout\n",
    "aug = iaa.Sequential([\n",
    "    iaa.CoarseDropout(p=0.05, size_percent=(1/8))\n",
    "])\n",
    "\n",
    "# Apply augmentation synchronously\n",
    "images_aug_list = aug(\n",
    "    images=[image]\n",
    ")\n",
    "\n",
    "# Retrieve augmented results\n",
    "masked_image = images_aug_list[0]\n",
    "\n",
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(masked_image)\n",
    "axs[1].imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Create train and validation directories\n",
    "os.makedirs('Train/color', exist_ok=True)\n",
    "os.makedirs('Train/label', exist_ok=True)\n",
    "os.makedirs('Val/color', exist_ok=True)\n",
    "os.makedirs('Val/label', exist_ok=True)\n",
    "\n",
    "image_dir = 'TrainVal/color'\n",
    "label_dir = 'TrainVal/label'\n",
    "\n",
    "species_files = {}\n",
    "\n",
    "# Collect image files with corresponding labels, grouped by species\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        label_filename = filename.replace('.jpg', '.png')\n",
    "        label_path = os.path.join(label_dir, label_filename)\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Skipping {filename} (label not found)\")\n",
    "            continue\n",
    "        species = filename.split('_')[0]\n",
    "        if species not in species_files:\n",
    "            species_files[species] = []\n",
    "        species_files[species].append(filename)\n",
    "\n",
    "# Process each species to split and move files\n",
    "for species, files in species_files.items():\n",
    "    random.shuffle(files)\n",
    "    split_idx = int(0.8 * len(files))\n",
    "    train_files = files[:split_idx]\n",
    "    val_files = files[split_idx:]\n",
    "    \n",
    "    # Move training data\n",
    "    for file in train_files:\n",
    "        # Move image\n",
    "        src_img = os.path.join(image_dir, file)\n",
    "        dst_img = os.path.join('Train/color', file)\n",
    "        shutil.move(src_img, dst_img)\n",
    "        # Move label\n",
    "        label_file = file.replace('.jpg', '.png')\n",
    "        src_label = os.path.join(label_dir, label_file)\n",
    "        dst_label = os.path.join('Train/label', label_file)\n",
    "        shutil.move(src_label, dst_label)\n",
    "    \n",
    "    # Move validation data\n",
    "    for file in val_files:\n",
    "        src_img = os.path.join(image_dir, file)\n",
    "        dst_img = os.path.join('Val/color', file)\n",
    "        shutil.move(src_img, dst_img)\n",
    "        # Move label\n",
    "        label_file = file.replace('.jpg', '.png')\n",
    "        src_label = os.path.join(label_dir, label_file)\n",
    "        dst_label = os.path.join('Val/label', label_file)\n",
    "        shutil.move(src_label, dst_label)\n",
    "\n",
    "print(\"Dataset split into Train and Val folders successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_aug = iaa.Grayscale(alpha=1.0, from_colorspace=\"RGB\")\n",
    "\n",
    "image_gray = grayscale_aug(image=image)\n",
    "\n",
    "plt.imshow(image_gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = iaa.AdditiveLaplaceNoise(scale=(0.1*255, 0.3*255), per_channel=True)\n",
    "image_laplace = laplace(image=image)\n",
    "\n",
    "plt.imshow(image_laplace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = iaa.AverageBlur(k=(12))\n",
    "\n",
    "image_blur = blur(image=image)\n",
    "\n",
    "plt.imshow(image_blur)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast = iaa.LinearContrast((0.2, 0.6))\n",
    "\n",
    "# Apply to an image (or batch)\n",
    "image_contrast = contrast(image=image)\n",
    "\n",
    "plt.imshow(image_contrast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "def combine_images(image1_path, image2_path, output_path=None):\n",
    "    # Open images\n",
    "    img1 = Image.open(image1_path)\n",
    "    img2 = Image.open(image2_path)\n",
    "    \n",
    "    # Get dimensions\n",
    "    w1, h1 = img1.size\n",
    "    w2, h2 = img2.size\n",
    "    \n",
    "    # Determine orientations and longest edges\n",
    "    def get_orientation(w, h):\n",
    "        return 'portrait' if h > w else 'landscape'\n",
    "    \n",
    "    orientation1 = get_orientation(w1, h1)\n",
    "    orientation2 = get_orientation(w2, h2)\n",
    "\n",
    "    if orientation1 != orientation2:\n",
    "        print(\"no merge\")\n",
    "        raise BaseException(\"no merge\")\n",
    "    \n",
    "    # Determine concatenation direction\n",
    "    if orientation1 == orientation2:\n",
    "        direction = 'horizontal' if orientation1 == 'portrait' else 'vertical'\n",
    "    else:\n",
    "        le1 = max(w1, h1)\n",
    "        le2 = max(w2, h2)\n",
    "        direction = 'horizontal' if le1 > le2 and orientation1 == 'portrait' or le2 > le1 and orientation2 == 'portrait' else 'vertical'\n",
    "\n",
    "    # Calculate scaling factors\n",
    "    if direction == 'horizontal':\n",
    "        # Scale to fit combined width = 512, height <= 512\n",
    "        total_width = w1 + w2\n",
    "        scale = min(512/total_width, 512/max(h1, h2))\n",
    "    else:\n",
    "        # Scale to fit combined height = 512, width <= 512\n",
    "        total_height = h1 + h2\n",
    "        scale = min(512/total_height, 512/max(w1, w2))\n",
    "\n",
    "    # Resize both images proportionally\n",
    "    def resize_img(img, original_w, original_h):\n",
    "        new_w = math.floor(original_w * scale)\n",
    "        new_h = math.floor(original_h * scale)\n",
    "        return img.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
    "\n",
    "    img1_resized = resize_img(img1, w1, h1)\n",
    "    img2_resized = resize_img(img2, w2, h2)\n",
    "\n",
    "    # Create combined image\n",
    "    if direction == 'horizontal':\n",
    "        combined_width = img1_resized.width + img2_resized.width\n",
    "        combined_height = max(img1_resized.height, img2_resized.height)\n",
    "        combined = Image.new('RGB', (combined_width, combined_height))\n",
    "        combined.paste(img1_resized, (0, 0))\n",
    "        combined.paste(img2_resized, (img1_resized.width, 0))\n",
    "    else:\n",
    "        combined_height = img1_resized.height + img2_resized.height\n",
    "        combined_width = max(img1_resized.width, img2_resized.width)\n",
    "        combined = Image.new('RGB', (combined_width, combined_height))\n",
    "        combined.paste(img1_resized, (0, 0))\n",
    "        combined.paste(img2_resized, (0, img1_resized.height))\n",
    "\n",
    "    # Center in 512x512 canvas\n",
    "    final_img = Image.new('RGB', (512, 512), (0, 0, 0))\n",
    "    x_offset = (512 - combined.width) // 2\n",
    "    y_offset = (512 - combined.height) // 2\n",
    "    final_img.paste(combined, (x_offset, y_offset))\n",
    "\n",
    "    if output_path:\n",
    "        final_img.save(output_path)\n",
    "    return final_img\n",
    "\n",
    "# Usage\n",
    "combined = combine_images(\"Train/label/beagle_154.png\", \"Train/label/beagle_145.png\")\n",
    "\n",
    "plt.imshow(combined)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
