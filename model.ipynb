{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, din, dout):\n",
    "        super().__init__()\n",
    "        self.down = nn.Sequential(\n",
    "            nn.Conv2d(din, dout, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(dout),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dout, dout, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(dout),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.down(x)\n",
    "    \n",
    "class up(nn.Module):\n",
    "    def __init__(self, din, dout):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Conv2d(din, dout, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(dout),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(dout, dout, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(dout),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "class unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.scale = 3 # maybe using the original channels might be better\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.down1 = down(3, self.scale * 64)\n",
    "        self.down2 = down(self.scale * 64, self.scale * 128)\n",
    "        self.down3 = down(self.scale * 128, self.scale * 256)\n",
    "        self.down4 = down(self.scale * 256, self.scale * 512)\n",
    "        self.down5 = down(self.scale * 512, self.scale * 1024)\n",
    "        self.up1 = up(self.scale * 1024, self.scale * 512)\n",
    "        self.up2 = up(self.scale * 512, self.scale * 256)\n",
    "        self.up3 = up(self.scale * 256, self.scale * 128)\n",
    "        self.up4 = up(self.scale * 128, self.scale * 64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.upconv1 = nn.Conv2d(self.scale * 1024, self.scale * 512, kernel_size=3, padding=1)\n",
    "        self.upconv2 = nn.Conv2d(self.scale * 512, self.scale * 256, kernel_size=3, padding=1)\n",
    "        self.upconv3 = nn.Conv2d(self.scale * 256, self.scale * 128, kernel_size=3, padding=1)\n",
    "        self.upconv4 = nn.Conv2d(self.scale * 128, self.scale * 64, kernel_size=3, padding=1)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(self.scale * 64, 4, kernel_size=1),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(self.maxpool(x1))\n",
    "        x3 = self.down3(self.maxpool(x2))\n",
    "        x4 = self.down4(self.maxpool(x3))\n",
    "        x5 = self.down5(self.maxpool(x4))\n",
    "        x6 = self.up1(torch.cat([x4, self.upconv1(self.upsample(x5))], dim=1))\n",
    "        x7 = self.up2(torch.cat([x3, self.upconv2(self.upsample(x6))], dim=1))\n",
    "        x8 = self.up3(torch.cat([x2, self.upconv3(self.upsample(x7))], dim=1))\n",
    "        x9 = self.up4(torch.cat([x1, self.upconv4(self.upsample(x8))], dim=1))\n",
    "        pre_output = self.output(x9)\n",
    "        return torch.argmax(pre_output, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, PILToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "from torchvision.io import decode_image\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.img_names = sorted([os.path.splitext(filename)[0] for filename in os.listdir(img_dir)])\n",
    "        self.len = len(self.img_names)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = decode_image(os.path.join(self.img_dir, self.img_names[idx] + \".jpg\")).float()/255\n",
    "        label = decode_image(os.path.join(self.label_dir, self.img_names[idx] + \".png\"))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return img.unsqueeze(0), label\n",
    "    \n",
    "def display_img_label(data, idx):\n",
    "    img, label = data[idx]\n",
    "    figure = plt.figure(figsize=(10,20))\n",
    "    figure.add_subplot(1, 2, 1)\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "    figure.add_subplot(1, 2, 2)\n",
    "    plt.imshow(label.permute(1, 2, 0), cmap='grey')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "class target_remap(object):\n",
    "    def __call__(self, img):\n",
    "        img[img == 255] = 3\n",
    "        return img\n",
    "\n",
    "\n",
    "training_data = dataset(\"rtrain/color\", \"rtrain/label\", target_transform=target_remap())\n",
    "\n",
    "test_data = dataset(\"rtest/color\", \"rtest/label\", target_transform=target_remap())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * 64 + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\nAvg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "model = unet()\n",
    "\n",
    "img, label = training_data[0]\n",
    "\n",
    "res = model(img)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "epochs = 10\n",
    "# for t in range(epochs):\n",
    "#     print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "#     train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "#     test_loop(test_dataloader, model, loss_fn)\n",
    "# print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
