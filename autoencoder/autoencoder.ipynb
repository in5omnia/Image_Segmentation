{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cec97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import TRUE\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from utils.dataset import *\n",
    "from utils.utils import *\n",
    "from utils.training import trainReconstruction, evalReconstruction\n",
    "from autoencoder.autoencoder import ReconstructionAutoencoder\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "target_batch_size = 64\n",
    "accumulation_steps = target_batch_size // batch_size\n",
    "\n",
    "training_data = dataset(\"datasets/astrain/color\", \"datasets/astrain/label\", target_transform=target_remap())\n",
    "validation_data = dataset(\"datasets/Val/color\", \"datasets/Val/label\", target_transform=target_remap())\n",
    "test_data = dataset(\"datasets/Test/color\", \"datasets/Test/label\", target_transform=target_remap())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=diff_size_collate)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, pin_memory=True,collate_fn=diff_size_collate)\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = ReconstructionAutoencoder(din=3, dout=3).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "MODEL_SAVE_DIR = \"tmp\"\n",
    "MODEL_NAME = \"tmp.pytorch\"\n",
    "start_epoch = 0\n",
    "recoverCheckpoint = False\n",
    "TARGET_SIZE = 256\n",
    "\n",
    "if recoverCheckpoint and os.path.isfile(f\"{MODEL_SAVE_DIR}/{MODEL_NAME}\"):\n",
    "    print(f\"Loading checkpoint from: {MODEL_SAVE_DIR}/{MODEL_NAME}\")\n",
    "    # Load the checkpoint dictionary; move tensors to the correct device\n",
    "    checkpoint = torch.load(f\"{MODEL_SAVE_DIR}/{MODEL_NAME}\", map_location=device, weights_only=False)\n",
    "\n",
    "    # Load model state\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(\" -> Model state loaded.\")\n",
    "\n",
    "    # Load optimizer state\n",
    "    try:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        print(\" -> Optimizer state loaded.\")\n",
    "    except Exception as e:\n",
    "        print(f\" -> Warning: Could not load optimizer state: {e}. Optimizer will start from scratch.\")\n",
    "\n",
    "    # Load training metadata\n",
    "    start_epoch = checkpoint.get(\"epoch\", 0) # Load last completed epoch, training continues from next one\n",
    "    best_val_loss = checkpoint.get(\"best_val_loss\", np.inf)\n",
    "\n",
    "    print(f\" -> Resuming training from epoch {start_epoch + 1}\")\n",
    "    loaded_notes = checkpoint.get(\"notes\", \"N/A\")\n",
    "    print(f\" -> Notes from checkpoint: {loaded_notes}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Checkpoint file not found at {MODEL_SAVE_DIR}/{MODEL_NAME}. Starting training from scratch.\")\n",
    "\n",
    "\n",
    "\n",
    "best_val_loss = np.inf\n",
    "EPOCHS = 100\n",
    "print(\"\\nStarting Training (Autoencoder)...\")\n",
    "for t in range(start_epoch, EPOCHS):\n",
    "    current_epoch = t + 1\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = trainReconstruction(train_dataloader, model, loss_fn, optimizer, accumulation_steps)\n",
    "\n",
    "    wrong_val_loss, correct_val_loss = evalReconstruction(val_dataloader, model, loss_fn, target_size=TARGET_SIZE)\n",
    "\n",
    "    # Save model based on validation val loss improvement\n",
    "    if correct_val_loss < best_val_loss:\n",
    "        print(f\"Validation loss improved ({best_val_loss:.6f} â†’ {correct_val_loss:.6f}). Saving model...\")\n",
    "        best_val_loss = correct_val_loss # Save corresponding loss\n",
    "        checkpoint_path = os.path.join(MODEL_SAVE_DIR, f\"{MODEL_NAME}\") # Changed name\n",
    "        checkpoint = {\n",
    "            \"epoch\": t + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "    else:\n",
    "        print(f\"Corresponding validation loss: {correct_val_loss:.6f} not better than {best_val_loss}\")\n",
    "\n",
    "    #print(f\"Wrong Validation loss: {wrong_val_loss:.6f}\")\n",
    "    print(f\"Train loss: {train_loss:.6f}\")\n",
    "\n",
    "    # PLot a training image reconstruction\n",
    "    img, label = training_data[0]\n",
    "    img = img.to(device)\n",
    "    res = model(img.unsqueeze(0))\n",
    "    plt.imshow(res[0].permute(1,2,0).cpu().detach().numpy())\n",
    "    plt.savefig(f\"drive/MyDrive/autoencoder/images/test{t}.png\", format=\"png\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Training Finished! ---\")\n",
    "print(f\"Best model saved to: {os.path.join(MODEL_SAVE_DIR, f'{MODEL_NAME}')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a050be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.training import start\n",
    "from utils.MetricsHistory import MetricsHistory\n",
    "from utils.weighted_loss import WeightedDiceCELoss\n",
    "from utils.utils import calculate_class_weights\n",
    "from utils.dataset import dataset, target_remap, diff_size_collate\n",
    "from autoencoder.autoencoder import SegmentationAutoencoder\n",
    "\n",
    "EVAL_IGNORE_INDEX = 3\n",
    "TRAIN_IGNORE_INDEX = None\n",
    "NUM_CLASSES = 4\n",
    "MODEL_NAME = \"tmp.pytorch\"\n",
    "MODEL_SAVE_DIR = \"tmp\"\n",
    "LOAD = False\n",
    "SAVE = False\n",
    "EPOCHS = 100\n",
    "WEIGHT_DECAY = 0.01\n",
    "TARGET_SIZE = 256\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "target_batch_size = 64\n",
    "batch_size = 64\n",
    "\n",
    "# With Augmentation\n",
    "training_data = dataset(\"datasets/astrain/color\", \"datasets/astrain/label\", target_transform=target_remap())\n",
    "val_data = dataset(\"datasets/Val/color\", \"datasets/Val/label\", target_transform=target_remap())\n",
    "test_data = dataset(\"datasets/Test/color\", \"datasets/Test/label\", target_transform=target_remap())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=diff_size_collate)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=diff_size_collate)\n",
    "\n",
    "\n",
    "# Class Weights\n",
    "class_weight = Tensor([0.33265044664009075, 1.669423957743164, 1.9979255956167454, 0.0])\n",
    "class_weight = Tensor([0.30711034803008996, 1.5412496145750956, 1.8445296893647247, 0.30711034803008996])\n",
    "class_weight = Tensor([0.2046795970925636, 1.0271954434416883, 1.2293222812780409, 1.5388026781877073])\n",
    "# class_weight = [1, 1, 1, 1]\n",
    "# class_weight = calculate_class_weights(training_data, 4, None, \"dataset\")\n",
    "class_weight = class_weight.to(device)\n",
    "\n",
    "accumulation_steps = target_batch_size // batch_size\n",
    "\n",
    "# Model\n",
    "# pretrained_encoder_path = \"/content/drive/MyDrive/autoencoder/256_with_aug_LR1e-3/checkpoint_256_with_aug_TargetSize256.pytorch\"\n",
    "# model = SegmentationAutoencoder(3, 4, pretrained_encoder_path).to(device)\n",
    "model = SegmentationAutoencoder(3, 4).to(device)\n",
    "\n",
    "# Loses\n",
    "train_loss_fn = WeightedDiceCELoss(ignore_index=TRAIN_IGNORE_INDEX, smooth_dice=1, class_weights=class_weight)\n",
    "val_loss_fn = WeightedDiceCELoss(ignore_index=EVAL_IGNORE_INDEX, class_weights=class_weight)\n",
    "\n",
    "# train_loss_fn = nn.CrossEntropyLoss(weight=class_weight)\n",
    "# val_loss_fn = nn.CrossEntropyLoss(weight=class_weight, ignore_index=EVAL_IGNORE_INDEX)\n",
    "\n",
    "# train_loss_fn = nn.CrossEntropyLoss()\n",
    "# val_loss_fn = nn.CrossEntropyLoss(ignore_index=EVAL_IGNORE_INDEX)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = None\n",
    "\n",
    "# Metric History\n",
    "agg = MetricsHistory(NUM_CLASSES, EVAL_IGNORE_INDEX)\n",
    "\n",
    "# Training Pipiline\n",
    "start(\n",
    "    model_save_dir=MODEL_SAVE_DIR,\n",
    "    model_save_name=MODEL_NAME,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    accumulation_steps=accumulation_steps,\n",
    "    device=device,\n",
    "    train_loss_fn=train_loss_fn,\n",
    "    val_loss_fn=val_loss_fn,\n",
    "    scheduler=scheduler,\n",
    "    agg=agg,\n",
    "    load=LOAD,\n",
    "    save=SAVE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    ignore_index=EVAL_IGNORE_INDEX,\n",
    "    target_size=TARGET_SIZE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d097991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
