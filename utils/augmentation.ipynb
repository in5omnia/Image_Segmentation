{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# Padding augmenter\n",
    "pad_aug = iaa.PadToAspectRatio(\n",
    "    1.0, # Keep aspect ratio\n",
    "    position=\"center\",\n",
    "    pad_mode=\"constant\",\n",
    "    pad_cval=0\n",
    ")\n",
    "\n",
    "# Resizers for Image and Labels\n",
    "resize_img = iaa.Resize(256, interpolation=\"cubic\")\n",
    "resize_mask = iaa.Resize(256, interpolation=\"nearest\")\n",
    "\n",
    "# Function to resize images\n",
    "def image_resizer(images, random_state, parents, hooks):\n",
    "    \"\"\"\n",
    "    Resizes the images using the resize_img augmenter.\n",
    "    Args:\n",
    "        images (list): A list of images to resize.\n",
    "        random_state: Random state for augmentation.\n",
    "        parents: Parents for augmentation.\n",
    "        hooks: Hooks for augmentation.\n",
    "    Returns:\n",
    "        list: A list of resized images.\n",
    "    \"\"\"\n",
    "    return [resize_img.augment_image(img) for img in images]\n",
    "\n",
    "# Function to resize masks\n",
    "def label_resizer(segmaps, random_state, parents, hooks):\n",
    "    \"\"\"\n",
    "    Resizes the segmentation masks using the resize_mask augmenter.\n",
    "    Args:\n",
    "        segmaps (list): A list of SegmentationMapsOnImage objects to resize.\n",
    "        random_state: Random state for augmentation.\n",
    "        parents: Parents for augmentation.\n",
    "        hooks: Hooks for augmentation.\n",
    "    Returns:\n",
    "        list: A list of resized SegmentationMapsOnImage objects.\n",
    "    \"\"\"\n",
    "    new_segmaps = []\n",
    "    for segmap in segmaps:\n",
    "        new_arr = resize_mask.augment_image(segmap.arr) # Resize the mask array.\n",
    "        new_segmaps.append(SegmentationMapsOnImage(new_arr, shape=new_arr.shape)) # Create a new SegmentationMapsOnImage object with the resized array.\n",
    "    return new_segmaps\n",
    "\n",
    "# Resizing augmenter\n",
    "resize_aug = iaa.Sequential([\n",
    "    pad_aug, # Apply padding to maintain aspect ratio.\n",
    "    iaa.Lambda( # Apply lambda to resize images and masks.\n",
    "        func_images=image_resizer, # Function to resize images.\n",
    "        func_segmentation_maps=label_resizer, # Function to resize segmentation masks.\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# Applies rotation augmentation to both images and segmentation maps\n",
    "rotation_aug = iaa.Sequential([\n",
    "    iaa.Affine(\n",
    "        rotate=(45, 315), # Rotation angle\n",
    "        fit_output=True, # Maintain full rotated image\n",
    "        mode=\"constant\",\n",
    "        cval=0,\n",
    "        backend=\"cv2\"\n",
    "    ),\n",
    "    resize_aug\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "from imgaug.imgaug import SegmentationMapsOnImage\n",
    "\n",
    "class CenterSquareCropAugmenter(iaa.Augmenter):\n",
    "    \"\"\"\n",
    "    CenterSquareCropAugmenter crops images to a square shape, centered.\n",
    "    Args:\n",
    "        name (str, optional): Name of the augmenter. Defaults to None.\n",
    "        deterministic (bool, optional): Whether the augmentation is deterministic. Defaults to False.\n",
    "        random_state (None, optional): Random state. Defaults to None.\n",
    "    \"\"\"\n",
    "    def __init__(self, name=None, deterministic=False, random_state=None):\n",
    "        super(CenterSquareCropAugmenter, self).__init__(\n",
    "            name=name, deterministic=deterministic, random_state=random_state)\n",
    "        self.cropper = iaa.CropToAspectRatio(1.0, position=\"center\") # Square cropper\n",
    "       \n",
    "    def _augment_images(self, images, random_state, parents, hooks):\n",
    "        \"\"\"\n",
    "        Applies the center square crop to a list of images.\n",
    "        Args:\n",
    "            images (list of numpy.ndarray): List of images.\n",
    "            random_state (numpy.random.RandomState): Random state.\n",
    "            parents (imgaug.parameters.StochasticParameter): Parents.\n",
    "            hooks (imgaug.hook.HooksImages): Hooks.\n",
    "        Returns:\n",
    "            list of numpy.ndarray: List of cropped images.\n",
    "        \"\"\"\n",
    "        return [self.cropper.augment_image(img) for img in images]\n",
    "    \n",
    "    def _augment_segmentation_maps(self, segmaps, random_state, parents, hooks):\n",
    "        \"\"\"\n",
    "        Applies the center square crop to segmentation maps.\n",
    "        Args:\n",
    "            segmaps (list of imgaug.imgaug.SegmentationMapsOnImage): List of segmentation maps.\n",
    "            random_state (numpy.random.RandomState): Random state.\n",
    "            parents (imgaug.parameters.StochasticParameter): Parents.\n",
    "            hooks (imgaug.hook.HooksImages): Hooks.\n",
    "        Returns:\n",
    "            list of imgaug.imgaug.SegmentationMapsOnImage: List of cropped segmentation maps.\n",
    "        \"\"\"\n",
    "        out = []\n",
    "        for segmap in segmaps:\n",
    "            cropped_arr = self.cropper.augment_image(segmap.arr)\n",
    "            out.append(SegmentationMapsOnImage(cropped_arr, shape=cropped_arr.shape))\n",
    "        return out\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class RandomSquareCropAugmenter(iaa.Augmenter):\n",
    "    \"\"\"\n",
    "    RandomSquareCropAugmenter crops images to a square shape, randomly.\n",
    "    Args:\n",
    "        crop_factor (float, optional): Ratio of the smallest edge to use for the square. Defaults to 2/3.\n",
    "        name (str, optional): Name of the augmenter. Defaults to None.\n",
    "        deterministic (bool, optional): Whether the augmentation is deterministic. Defaults to False.\n",
    "        random_state (None, optional): Random state. Defaults to None.\n",
    "    \"\"\"\n",
    "    def __init__(self, crop_factor=2/3, name=None, deterministic=False, random_state=None):\n",
    "        \"\"\"\n",
    "        crop_factor: Ratio of the smallest edge to use for the square.\n",
    "        \"\"\"\n",
    "        super(RandomSquareCropAugmenter, self).__init__(\n",
    "            name=name, deterministic=deterministic, random_state=random_state)\n",
    "        self.crop_factor = crop_factor\n",
    "    \n",
    "    def _augment_images(self, images, random_state, parents, hooks):\n",
    "        \"\"\"\n",
    "        Applies the random square crop to a list of images.\n",
    "        Args:\n",
    "            images (list of numpy.ndarray): List of images.\n",
    "            random_state (numpy.random.RandomState): Random state.\n",
    "            parents (imgaug.parameters.StochasticParameter): Parents.\n",
    "            hooks (imgaug.hook.HooksImages): Hooks.\n",
    "        Returns:\n",
    "            list of numpy.ndarray: List of cropped images.\n",
    "        \"\"\"\n",
    "        out_images = []\n",
    "        for img in images:\n",
    "            H, W = img.shape[:2]\n",
    "            min_side = min(H, W)\n",
    "            crop_size = int(min_side * self.crop_factor)\n",
    "            max_x = W - crop_size\n",
    "            max_y = H - crop_size\n",
    "            x1 = random_state.randint(0, max_x + 1)\n",
    "            y1 = random_state.randint(0, max_y + 1)\n",
    "            cropped_img = img[y1: y1 + crop_size, x1: x1 + crop_size]\n",
    "            out_images.append(cropped_img)\n",
    "        return out_images\n",
    "\n",
    "    def _augment_segmentation_maps(self, segmaps, random_state, parents, hooks):\n",
    "        \"\"\"\n",
    "        Applies the random square crop to segmentation maps.\n",
    "        Args:\n",
    "            segmaps (list of imgaug.imgaug.SegmentationMapsOnImage): List of segmentation maps.\n",
    "            random_state (numpy.random.RandomState): Random state.\n",
    "            parents (imgaug.parameters.StochasticParameter): Parents.\n",
    "            hooks (imgaug.hook.HooksImages): Hooks.\n",
    "        Returns:\n",
    "            list of imgaug.imgaug.SegmentationMapsOnImage: List of cropped segmentation maps.\n",
    "        \"\"\"\n",
    "        out_segmaps = []\n",
    "        for segmap in segmaps:\n",
    "            arr = segmap.arr\n",
    "            H, W = arr.shape[:2]\n",
    "            min_side = min(H, W)\n",
    "            crop_size = int(min_side * self.crop_factor)\n",
    "            max_x = W - crop_size\n",
    "            max_y = H - crop_size\n",
    "            x1 = random_state.randint(0, max_x + 1)\n",
    "            y1 = random_state.randint(0, max_y + 1)\n",
    "            cropped_arr = arr[y1: y1 + crop_size, x1: x1 + crop_size]\n",
    "            out_segmaps.append(SegmentationMapsOnImage(cropped_arr, shape=cropped_arr.shape))\n",
    "        return out_segmaps\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return [self.crop_factor]\n",
    "    \n",
    "# Center crop augmenter.\n",
    "center_crop_aug = iaa.Sequential([CenterSquareCropAugmenter(), resize_aug])\n",
    "\n",
    "# Random square crop augmenter.\n",
    "random_crop_aug = iaa.Sequential([RandomSquareCropAugmenter(), resize_aug])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "# Define augmentation for masking images.\n",
    "mask_im_aug = iaa.Sequential([\n",
    "    iaa.CoarseDropout(p=0.15, size_percent=(1/50), random_state=2)\n",
    "])\n",
    "\n",
    "# Define augmentation for masking labels.\n",
    "mask_label_aug = iaa.Sequential([\n",
    "    iaa.CoarseDropout(p=0.15, size_percent=(1/50), random_state=2)\n",
    "])\n",
    "\n",
    "def random_masking_labels(segmaps, random_state, parents, hooks):\n",
    "    \"\"\"\n",
    "    Applies random masking to segmentation maps.\n",
    "    Args:\n",
    "        segmaps: Input segmentation maps.\n",
    "        random_state: Random state for augmentation.\n",
    "        parents: Parent objects.\n",
    "        hooks: Hooks for augmentation.\n",
    "    Returns:\n",
    "        List of augmented segmentation maps.\n",
    "    \"\"\"\n",
    "    new_segmaps = []\n",
    "    for segmap in segmaps:\n",
    "        # Convert segmentation map array to uint8 for augmentation.\n",
    "        segmap_arr_uint8 = segmap.arr.astype(np.uint8)\n",
    "        # Apply mask_label_aug to the segmentation map.\n",
    "        new_arr = mask_label_aug.augment_image(segmap_arr_uint8)\n",
    "        # Create a new SegmentationMapsOnImage object with the augmented array.\n",
    "        new_segmaps.append(SegmentationMapsOnImage(new_arr, shape=new_arr.shape))\n",
    "    return new_segmaps\n",
    "\n",
    "# Random Masking augmentation\n",
    "masking_aug = iaa.Sequential([\n",
    "    iaa.Lambda(\n",
    "        func_images=lambda images, rs, parents, hooks: [mask_im_aug.augment_image(img) for img in images],\n",
    "        func_segmentation_maps=random_masking_labels\n",
    "    ),\n",
    "    resize_aug # Apply resizing after masking\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale augmentation\n",
    "grayscale = iaa.Grayscale(alpha=1.0, from_colorspace=\"RGB\")\n",
    "grayscale_aug = iaa.Sequential([\n",
    "    grayscale,\n",
    "    resize_aug\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplace Noise Augmentation\n",
    "laplace = iaa.AdditiveLaplaceNoise(scale=(0.1*255, 0.3*255), per_channel=True)\n",
    "laplace_aug = iaa.Sequential([\n",
    "    laplace,\n",
    "    resize_aug\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur Augmentation\n",
    "blur = iaa.AverageBlur(k=(12))\n",
    "blur_aug = iaa.Sequential([\n",
    "    blur,\n",
    "    resize_aug\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast Augmentation\n",
    "contrast = iaa.LinearContrast((0.2, 0.6))\n",
    "contrast_aug = iaa.Sequential([\n",
    "    contrast,\n",
    "    resize_aug\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "import os \n",
    "import numpy as np \n",
    "from utils import convert_rgb_label_to_classes\n",
    "\n",
    "\n",
    "def combine_images_preserve_aspect_ratio(image1_path, image2_path, output_path=None, is_label=False):\n",
    "    \"\"\"\n",
    "    Combines two images, preserving aspect ratio, centers on 256x256, then optionally converts to a 1-channel class map.\n",
    "    If is_label is True, converts the final RGB image to a 1-channel class map\n",
    "    using convert_rgb_label_to_classes before saving/returning.\n",
    "\n",
    "    Args:\n",
    "        image1_path (str): Path to the first image.\n",
    "        image2_path (str): Path to the second image.\n",
    "        output_path (str, optional): Path to save the final image. Defaults to None.\n",
    "        is_label (bool, optional): If True, apply label conversion. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: The final combined image (RGB or L mode).\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError, ValueError, IOError, RuntimeError as before.\n",
    "    \"\"\"\n",
    "    TARGET_DIMENSION = 256\n",
    "    RESAMPLE_METHOD = Image.Resampling.NEAREST\n",
    "\n",
    "    def load_image(path):\n",
    "        \"\"\"\n",
    "        Loads an image from the given path and converts it to RGB mode.\n",
    "        Handles RGBA, LA, and P modes by converting them to RGB to avoid issues.\n",
    "\n",
    "        Args:\n",
    "            path (str): The path to the image file.\n",
    "\n",
    "        Returns:\n",
    "            PIL.Image.Image: The loaded image in RGB mode.\n",
    "        \"\"\"\n",
    "        img = Image.open(path)\n",
    "        if img.mode == 'RGBA':\n",
    "            # Create a new RGB image with a black background and paste the image, masking the alpha channel\n",
    "            background = Image.new('RGB', img.size, (0, 0, 0))\n",
    "            background.paste(img, mask=img.split()[-1])\n",
    "            img = background\n",
    "        elif img.mode == 'LA':\n",
    "            # Convert LA to RGBA, create a new RGB image with a black background, and paste the image, masking the alpha channel\n",
    "            rgba_img = img.convert('RGBA')\n",
    "            background = Image.new('RGB', rgba_img.size, (0, 0, 0))\n",
    "            background.paste(rgba_img, mask=rgba_img.split()[-1])\n",
    "            img = background\n",
    "        elif img.mode == 'P':\n",
    "                # Convert P to RGBA, create a new RGB image with a black background, and paste the image, masking the alpha channel\n",
    "                rgba_img = img.convert('RGBA')\n",
    "                background = Image.new('RGB', rgba_img.size, (0, 0, 0))\n",
    "                background.paste(rgba_img, mask=rgba_img.split()[-1])\n",
    "                img = background\n",
    "        return img.convert('RGB')\n",
    "\n",
    "\n",
    "    img1 = load_image(image1_path)\n",
    "    img2 = load_image(image2_path)\n",
    "\n",
    "    # 2. Dimensions & Orientation\n",
    "    w1, h1 = img1.size\n",
    "    w2, h2 = img2.size\n",
    "    \n",
    "    def get_orientation(w, h): \n",
    "        \"\"\"\n",
    "        Determine the orientation of an image (portrait or landscape).\n",
    "\n",
    "        Args:\n",
    "            w (int): Width of the image.\n",
    "            h (int): Height of the image.\n",
    "\n",
    "        Returns:\n",
    "            str: 'portrait' if the image is portrait, 'landscape' otherwise.\n",
    "        \"\"\"\n",
    "        return 'portrait' if h > w else 'landscape'\n",
    "    \n",
    "    orientation1 = get_orientation(w1, h1)\n",
    "    orientation2 = get_orientation(w2, h2)\n",
    "    \n",
    "    if orientation1 != orientation2:\n",
    "        print(f\" Mismatched orientations ({orientation1} vs {orientation2}) for {os.path.basename(image1_path)}, {os.path.basename(image2_path)}\")\n",
    "        return None\n",
    "    orientation = orientation1\n",
    "\n",
    "    # 3. Calculate Scale\n",
    "    if orientation == 'portrait':\n",
    "        total_original_major_dim = w1 + w2\n",
    "        if total_original_major_dim == 0:\n",
    "            return None\n",
    "        scale = TARGET_DIMENSION / total_original_major_dim\n",
    "    else: # landscape\n",
    "        total_original_major_dim = h1 + h2\n",
    "        if total_original_major_dim == 0:\n",
    "            return None\n",
    "        scale = TARGET_DIMENSION / total_original_major_dim\n",
    "\n",
    "    # 4. Calculate Scaled Dimensions\n",
    "    scaled_w1 = max(1, math.ceil(w1 * scale))\n",
    "    scaled_h1 = max(1, math.ceil(h1 * scale))\n",
    "    scaled_w2 = max(1, math.ceil(w2 * scale))\n",
    "    scaled_h2 = max(1, math.ceil(h2 * scale))\n",
    "\n",
    "    # 5. Adjust for Exact Fit\n",
    "    final_w1, final_h1 = scaled_w1, scaled_h1\n",
    "    final_w2, final_h2 = scaled_w2, scaled_h2\n",
    "    if orientation == 'portrait':\n",
    "        diff = (scaled_w1 + scaled_w2) - TARGET_DIMENSION\n",
    "        if diff > 0:\n",
    "            final_w1 -= diff if scaled_w1 >= scaled_w2 else 0\n",
    "            final_w2 -= diff if scaled_w2 > scaled_w1 else 0\n",
    "    else:\n",
    "        diff = (scaled_h1 + scaled_h2) - TARGET_DIMENSION\n",
    "        if diff > 0: \n",
    "            final_h1 -= diff if scaled_h1 >= scaled_h2 else 0\n",
    "            final_h2 -= diff if scaled_h2 > scaled_h1 else 0\n",
    "            \n",
    "    final_w1, final_h1, final_w2, final_h2 = max(1, final_w1), max(1, final_h1), max(1, final_w2), max(1, final_h2)\n",
    "\n",
    "    # 6. Resize Images\n",
    "\n",
    "    img1_resized = img1.resize((final_w1, final_h1), RESAMPLE_METHOD)\n",
    "    img2_resized = img2.resize((final_w2, final_h2), RESAMPLE_METHOD)\n",
    "\n",
    "\n",
    "    # 7. Create Combined Strip\n",
    "    if orientation == 'portrait':\n",
    "        combined_w, combined_h = TARGET_DIMENSION, max(final_h1, final_h2)\n",
    "        combined = Image.new('RGB', (combined_w, combined_h), (0, 0, 0))\n",
    "        combined.paste(img1_resized, (0, 0))\n",
    "        combined.paste(img2_resized, (final_w1, 0))\n",
    "    else: # landscape\n",
    "        combined_w, combined_h = max(final_w1, final_w2), TARGET_DIMENSION\n",
    "        combined = Image.new('RGB', (combined_w, combined_h), (0, 0, 0))\n",
    "        combined.paste(img1_resized, (0, 0))\n",
    "        combined.paste(img2_resized, (0, final_h1))\n",
    "\n",
    "    # 8. Create Final Canvas & Center\n",
    "    final_img = Image.new('RGB', (TARGET_DIMENSION, TARGET_DIMENSION), (0, 0, 0))\n",
    "    paste_x = (TARGET_DIMENSION - combined.width) // 2\n",
    "    paste_y = (TARGET_DIMENSION - combined.height) // 2\n",
    "    final_img.paste(combined, (paste_x, paste_y))\n",
    "\n",
    "    # 9. Label Conversion\n",
    "    if is_label:\n",
    "        # Convert final PIL Image to NumPy array\n",
    "        final_img_np = np.array(final_img)\n",
    "        # Apply the RGB -> Class ID conversion\n",
    "        label_map_1channel = convert_rgb_label_to_classes(final_img_np)\n",
    "        # Convert the 1-channel NumPy array back to a PIL Image (mode 'L')\n",
    "        final_img = Image.fromarray(label_map_1channel, mode='L')\n",
    "\n",
    "\n",
    "    # 10. Save if output path is provided\n",
    "    if output_path:\n",
    "        final_img.save(output_path)\n",
    "\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation without merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "import math\n",
    "\n",
    "# Define a dictionary mapping augmenter names to their corresponding functions\n",
    "augmenter_dict = {\n",
    "    \"rotation\": rotation_aug,\n",
    "    \"center_crop\": center_crop_aug,\n",
    "    \"random_crop\": random_crop_aug,\n",
    "    \"masking\": masking_aug,\n",
    "    \"grayscale\": grayscale_aug,\n",
    "    \"laplace\": laplace_aug,\n",
    "    \"blur\": blur_aug,\n",
    "    \"contrast\": contrast_aug\n",
    "}\n",
    "\n",
    "# Calculate the number of augmenters\n",
    "num_augmenters = len(augmenter_dict) # Count based on the dictionary\n",
    "\n",
    "# Configuration\n",
    "folder_path = \"Train/color\" # Path to the folder containing color images\n",
    "label_folder_path = \"Train/label\" # Path to the folder containing label images\n",
    "save_color_dir = \"astrain/color\" # Directory to save augmented color images\n",
    "save_label_dir = \"astrain/label\" # Directory to save augmented label images\n",
    "majority_aug_factor = 1.5 # Augmentation factor to balance the dataset\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "os.makedirs(save_color_dir, exist_ok=True)\n",
    "os.makedirs(save_label_dir, exist_ok=True)\n",
    "\n",
    "# File Discovery and Classification\n",
    "print(\"Scanning for image files...\")\n",
    "filenames = [\n",
    "    f for f in os.listdir(folder_path)\n",
    "    if f.lower().endswith(('.jpg', '.png'))\n",
    "]\n",
    "# This section assumes that the file names can be used to identify the species\n",
    "\n",
    "def get_species(filename):\n",
    "    \"\"\"\n",
    "    Extracts the species name from a filename.\n",
    "    Args:\n",
    "        filename (str): The name of the file.\n",
    "    Returns:\n",
    "        str: The species name.\n",
    "    \"\"\"\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    parts = base.rsplit('_', 1)\n",
    "    return parts[0] if len(parts) > 1 else base\n",
    "\n",
    "# Define a set of cat species for classification\n",
    "cat_species = {\n",
    "    \"Russian_Blue\", \"Siamese\", \"Sphynx\", \"Maine_Coon\", \"Abyssinian\",\n",
    "    \"Bombay\", \"British_Shorthair\", \"Bengal\", \"Egyptian_Mau\", \"Persian\",\n",
    "    \"Ragdoll\", \"Birman\"\n",
    "}\n",
    "\n",
    "# Initialize lists to store cat and dog filenames\n",
    "cat_files = []\n",
    "dog_files = []\n",
    "for fname in filenames:\n",
    "    species = get_species(fname)\n",
    "    name_no_ext = os.path.splitext(fname)[0]\n",
    "    label_path_check = os.path.join(label_folder_path, name_no_ext + \".png\")\n",
    "    if species in cat_species:\n",
    "        cat_files.append(name_no_ext)\n",
    "    else:\n",
    "        dog_files.append(name_no_ext)\n",
    "\n",
    "# Get the number of cat and dog files\n",
    "N_cat = len(cat_files)\n",
    "N_dog = len(dog_files)\n",
    "\n",
    "print(f\"Initial counts: Cats = {N_cat}, Dogs = {N_dog}\")\n",
    "\n",
    "# Copy Original Files\n",
    "print(\"Processing originals with resize augmentation...\")\n",
    "all_original_files = cat_files + dog_files\n",
    "processed_count = 0\n",
    "\n",
    "# Ensure destination directories exist\n",
    "os.makedirs(save_color_dir, exist_ok=True)\n",
    "os.makedirs(save_label_dir, exist_ok=True)\n",
    "\n",
    "for fname in all_original_files:\n",
    "    orig_color_path = os.path.join(folder_path, fname + \".jpg\")\n",
    "    orig_label_path = os.path.join(label_folder_path, fname + \".png\")\n",
    "\n",
    "    # Define destination paths (using original base name)\n",
    "    dest_color_path = os.path.join(save_color_dir, fname + \".jpg\")\n",
    "    dest_label_path = os.path.join(save_label_dir, fname + \".png\")\n",
    "\n",
    "    # Read the input image and its label\n",
    "    img = imageio.v2.imread(orig_color_path)\n",
    "    label = imageio.v2.imread(orig_label_path)\n",
    "\n",
    "    # Create a segmentation map object\n",
    "    segmap = SegmentationMapsOnImage(label, shape=img.shape)\n",
    "\n",
    "    # Apply the resize augmentation to both image and label map\n",
    "    resized_img, resized_segmap = resize_aug(image=img, segmentation_maps=segmap)\n",
    "    resized_label = resized_segmap.get_arr()\n",
    "\n",
    "    if resized_img.ndim == 3 and resized_img.shape[2] == 4:\n",
    "        resized_img = resized_img[..., :3] # RGBA to RGB\n",
    "\n",
    "    resized_label = convert_rgb_label_to_classes(resized_label)\n",
    "\n",
    "    # Ensure correct data types before saving\n",
    "    resized_img = resized_img.astype(np.uint8)\n",
    "    resized_label = resized_label.astype(np.uint8)\n",
    "\n",
    "    # Save the processed (resized) images\n",
    "    imageio.imwrite(dest_color_path, resized_img)\n",
    "    imageio.imwrite(dest_label_path, resized_label)\n",
    "\n",
    "    processed_count += 1\n",
    "\n",
    "print(f\"Processed and saved {processed_count} original image/label pairs using resize_aug.\")\n",
    "\n",
    "\n",
    "# --- Calculate Augmentation Needs ---\n",
    "if N_cat == N_dog:\n",
    "    target_final_count = round(N_dog * majority_aug_factor)\n",
    "elif N_cat < N_dog:\n",
    "    target_final_count = round(N_dog * majority_aug_factor)\n",
    "else: # N_dog < N_cat\n",
    "    target_final_count = round(N_cat * majority_aug_factor)\n",
    "\n",
    "total_aug_cat_needed = max(0, target_final_count - N_cat)\n",
    "total_aug_dog_needed = max(0, target_final_count - N_dog)\n",
    "\n",
    "print(f\"Target final count per class: {target_final_count}\")\n",
    "print(f\"Total augmentations needed: Cats = {total_aug_cat_needed}, Dogs = {total_aug_dog_needed}\")\n",
    "\n",
    "num_cats_per_aug = math.ceil(total_aug_cat_needed / num_augmenters)\n",
    "num_dogs_per_aug = math.ceil(total_aug_dog_needed / num_augmenters)\n",
    "\n",
    "print(f\"Will select approximately {num_cats_per_aug} cats and {num_dogs_per_aug} dogs per augmenter.\")\n",
    "\n",
    "num_selected_cats = 0\n",
    "num_selected_dogs = 0\n",
    "\n",
    "# Augmentation Loop\n",
    "generated_aug_count = 0\n",
    "for i, (aug_name, aug_object) in enumerate(augmenter_dict.items()):\n",
    "    # Randomly select files for augmentation\n",
    "    selected_cats = random.choices(cat_files, k=num_cats_per_aug) if N_cat > 0 and num_cats_per_aug > 0 else []\n",
    "    selected_dogs = random.choices(dog_files, k=num_dogs_per_aug) if N_dog > 0 and num_dogs_per_aug > 0 else []\n",
    "    selected_files = selected_cats + selected_dogs\n",
    "    num_selected_cats += len(selected_cats)\n",
    "    num_selected_dogs += len(selected_dogs)\n",
    "\n",
    "    print(f\"\\nUsing augmenter '{aug_name}' ({i+1}/{num_augmenters}): processing {len(selected_files)} images ({len(selected_cats)} cats, {len(selected_dogs)} dogs)\")\n",
    "\n",
    "    processed_in_batch = 0\n",
    "    for fname in selected_files:\n",
    "        color_path = os.path.join(folder_path, fname + \".jpg\")\n",
    "        label_path = os.path.join(label_folder_path, fname + \".png\")\n",
    "\n",
    "        # Read images\n",
    "        img = imageio.v2.imread(color_path)\n",
    "        label = imageio.v2.imread(label_path)\n",
    "        segmap = SegmentationMapsOnImage(label, shape=img.shape)\n",
    "\n",
    "        # Apply the augmentation\n",
    "        augmented_img, augmented_segmap = aug_object(image=img, segmentation_maps=segmap)\n",
    "        augmented_label = augmented_segmap.get_arr()\n",
    "\n",
    "        if augmented_img.ndim == 3 and augmented_img.shape[2] == 4:\n",
    "                augmented_img = augmented_img[..., :3] # RGBA to RGB\n",
    "\n",
    "        augmented_label = convert_rgb_label_to_classes(augmented_label)\n",
    "\n",
    "        # Type casting\n",
    "        augmented_label = augmented_label.astype(np.uint8)\n",
    "        augmented_img = augmented_img.astype(np.uint8)\n",
    "\n",
    "        out_color_path = os.path.join(save_color_dir, f\"{fname}_{aug_name}_{processed_in_batch}.jpg\")\n",
    "        out_label_path = os.path.join(save_label_dir, f\"{fname}_{aug_name}_{processed_in_batch}.png\")\n",
    "\n",
    "        # Save the augmented images\n",
    "        imageio.imwrite(out_color_path, augmented_img)\n",
    "        imageio.imwrite(out_label_path, augmented_label)\n",
    "\n",
    "        generated_aug_count += 1\n",
    "        processed_in_batch += 1\n",
    "\n",
    "    print(f\"Augmenter '{aug_name}' finished. Processed {processed_in_batch} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation with merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "SOURCE_COLOR_DIR = \"Train/color\"\n",
    "SOURCE_LABEL_DIR = \"Train/label\"\n",
    "DEST_COLOR_DIR = \"astrain/color\"\n",
    "DEST_LABEL_DIR = \"astrain/label\"\n",
    "NUM_COMBINATIONS_PER_TYPE = 126\n",
    "\n",
    "cat_species = {\n",
    "    \"Russian_Blue\", \"Siamese\", \"Sphynx\", \"Maine_Coon\", \"Abyssinian\",\n",
    "    \"Bombay\", \"British_Shorthair\", \"Bengal\", \"Egyptian_Mau\", \"Persian\",\n",
    "    \"Ragdoll\", \"Birman\"\n",
    "}\n",
    "\n",
    "def get_species(filename):\n",
    "    \"\"\"\n",
    "    Extracts the species name from a filename.\n",
    "    Args:\n",
    "        filename (str): The name of the file.\n",
    "    Returns:\n",
    "        str: The species name or the base filename if no species is found.\n",
    "    \"\"\"\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    parts = base.rsplit('_', 1)\n",
    "    return parts[0] if len(parts) > 1 else base\n",
    "\n",
    "\n",
    "# 1. Create destination directories\n",
    "os.makedirs(DEST_COLOR_DIR, exist_ok=True)\n",
    "os.makedirs(DEST_LABEL_DIR, exist_ok=True)\n",
    "\n",
    "# 2. Scan source directory and classify files\n",
    "all_files_in_color = [\n",
    "    f for f in os.listdir(SOURCE_COLOR_DIR)\n",
    "    if f.lower().endswith(('.jpg', '.png')) # Assuming color can be jpg or png\n",
    "]\n",
    "\n",
    "\n",
    "cat_files = []\n",
    "dog_files = []\n",
    "\n",
    "for fname_ext in all_files_in_color:\n",
    "    fname_no_ext = os.path.splitext(fname_ext)[0]\n",
    "    label_path_check = os.path.join(SOURCE_LABEL_DIR, fname_no_ext + \".png\")\n",
    "\n",
    "\n",
    "    species = get_species(fname_ext)\n",
    "    if species in cat_species:\n",
    "        cat_files.append(fname_no_ext)\n",
    "    else:\n",
    "        dog_files.append(fname_no_ext)\n",
    "\n",
    "N_cat = len(cat_files)\n",
    "N_dog = len(dog_files)\n",
    "\n",
    "print(f\"Found {N_cat} cat images with labels.\")\n",
    "print(f\"Found {N_dog} dog images with labels.\")\n",
    "\n",
    "# Function to generate combinations for a specific type\n",
    "def generate_combinations(combo_type, files1_list, files2_list, num_required, output_prefix):\n",
    "    \"\"\"\n",
    "    Generates N combinations by selecting files from lists and calling combine_images.\n",
    "    Prints the source files used for each successful combination.\n",
    "\n",
    "    Args:\n",
    "        combo_type (str): Description (e.g., \"1 Cat + 1 Dog\")\n",
    "        files1_list (list): List of base filenames for the first image.\n",
    "        files2_list (list): List of base filenames for the second image.\n",
    "        num_required (int): Target number of successful combinations.\n",
    "        output_prefix (str): Prefix for output filenames (e.g., \"cat_dog\").\n",
    "    \"\"\"\n",
    "\n",
    "    combinations_done = 0\n",
    "    attempts = 0\n",
    "    max_attempts = num_required * 10\n",
    "\n",
    "    generated_pairs = set()\n",
    "    file1_base, file2_base = None, None\n",
    "\n",
    "    while combinations_done < num_required and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "\n",
    "        if files1_list is files2_list:\n",
    "            # If combining from the same list, sample 2 unique files.\n",
    "            if len(files1_list) < 2:\n",
    "                break\n",
    "            file1_base, file2_base = random.sample(files1_list, 2)\n",
    "        else:\n",
    "            # If combining from different lists, sample one from each.\n",
    "            if not files1_list or not files2_list:\n",
    "                break\n",
    "            file1_base = random.choice(files1_list)\n",
    "            file2_base = random.choice(files2_list)\n",
    "\n",
    "        pair_key = tuple(sorted((file1_base, file2_base)))\n",
    "        if pair_key in generated_pairs:\n",
    "            # Skip if this pair has already been generated.\n",
    "            continue\n",
    "\n",
    "        # Construct paths\n",
    "        img1_color_ext = \".jpg\"\n",
    "        img2_color_ext = \".jpg\"\n",
    "        img1_label_ext = \".png\"\n",
    "        img2_label_ext = \".png\"\n",
    "\n",
    "        img1_color_path = os.path.join(SOURCE_COLOR_DIR, file1_base + img1_color_ext)\n",
    "        img1_label_path = os.path.join(SOURCE_LABEL_DIR, file1_base + img1_label_ext)\n",
    "        img2_color_path = os.path.join(SOURCE_COLOR_DIR, file2_base + img2_color_ext)\n",
    "        img2_label_path = os.path.join(SOURCE_LABEL_DIR, file2_base + img2_label_ext)\n",
    "\n",
    "        # Define output paths\n",
    "        output_base_name = f\"{output_prefix}_{combinations_done}\"\n",
    "        output_color_path = os.path.join(DEST_COLOR_DIR, output_base_name + \".jpg\")\n",
    "        output_label_path = os.path.join(DEST_LABEL_DIR, output_base_name + \".png\")\n",
    "\n",
    "        # Combine color images\n",
    "        combined_color = combine_images_preserve_aspect_ratio(img1_color_path, img2_color_path, output_color_path)\n",
    "\n",
    "        # Combine label images\n",
    "        combined_label = combine_images_preserve_aspect_ratio(img1_label_path, img2_label_path, output_label_path, True)\n",
    "        \n",
    "        print(f\"\\n  Generated: {output_base_name}.jpg/.png using [{file1_base}{img1_color_ext}, {file2_base}{img2_color_ext}]\")\n",
    "\n",
    "        combinations_done += 1\n",
    "        generated_pairs.add(pair_key)\n",
    "\n",
    "\n",
    "# 1. 1 Cat + 1 Dog\n",
    "generate_combinations(\n",
    "    combo_type=\"1 Cat + 1 Dog\",\n",
    "    files1_list=cat_files,\n",
    "    files2_list=dog_files,\n",
    "    num_required=NUM_COMBINATIONS_PER_TYPE,\n",
    "    output_prefix=\"cat_dog\"\n",
    ")\n",
    "\n",
    "# 2. 2 Cats\n",
    "generate_combinations(\n",
    "    combo_type=\"2 Cats\",\n",
    "    files1_list=cat_files,\n",
    "    files2_list=cat_files,\n",
    "    num_required=NUM_COMBINATIONS_PER_TYPE,\n",
    "    output_prefix=\"cat_cat\"\n",
    ")\n",
    "\n",
    "# 3. 2 Dogs\n",
    "generate_combinations(\n",
    "    combo_type=\"2 Dogs\",\n",
    "    files1_list=dog_files,\n",
    "    files2_list=dog_files,\n",
    "    num_required=NUM_COMBINATIONS_PER_TYPE,\n",
    "    output_prefix=\"dog_dog\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Combination process finished. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import shutil \n",
    "from torchvision.io import read_image\n",
    "from PIL import Image \n",
    "from utils.dataset import target_remap\n",
    "\n",
    "def create_gaussian_heatmap(size=(256, 256), sigma=3.0):\n",
    "    \"\"\"\n",
    "    Creates a 2D heatmap array with a Gaussian spot centered at a random pixel.\n",
    "\n",
    "    Args:\n",
    "        size (tuple): The (height, width) dimensions of the heatmap array.\n",
    "        sigma (float): The standard deviation (spread) of the Gaussian function.\n",
    "                       Larger sigma means a wider, smoother spot.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D numpy array representing the heatmap (values typically 0-1).\n",
    "        tuple: The (y, x) coordinates of the chosen center pixel.\n",
    "    \"\"\"\n",
    "    height, width = size\n",
    "    if height <= 0 or width <= 0:\n",
    "        raise ValueError(\"Size dimensions must be positive integers.\")\n",
    "    if sigma <= 0:\n",
    "        raise ValueError(\"Sigma must be positive.\")\n",
    "\n",
    "    # 1. Create a black canvas (array of zeros)\n",
    "    heatmap = np.zeros((height, width), dtype=np.float32) # Use float for calculations\n",
    "\n",
    "    # 2. Pick a random center pixel\n",
    "    center_y = random.randint(0, height - 1)\n",
    "    center_x = random.randint(0, width - 1)\n",
    "    print(f\"Selected center pixel (y, x): ({center_y}, {center_x})\")\n",
    "\n",
    "    # 3. Create coordinate grids\n",
    "    y_coords, x_coords = np.indices((height, width))\n",
    "\n",
    "    # 4. Calculate the squared Euclidean distance from the center for each pixel\n",
    "    dist_sq = (x_coords - center_x)**2 + (y_coords - center_y)**2\n",
    "\n",
    "    # 5. Calculate the Gaussian function\n",
    "    heatmap = np.exp(-dist_sq / (2 * sigma**2))\n",
    "\n",
    "    return heatmap, (center_y, center_x)\n",
    "\n",
    "\n",
    "# --- Helper function for the selection process ---\n",
    "def select_dominant_class(heatmap, remapped_mask):\n",
    "    \"\"\"\n",
    "    Selects the dominant class in a mask based on heatmap scores.\n",
    "\n",
    "    Args:\n",
    "        heatmap (numpy.ndarray): The heatmap array.\n",
    "        remapped_mask (numpy.ndarray): The remapped mask array.\n",
    "\n",
    "    Returns:\n",
    "        int: The selected class (0 if no class is dominant).\n",
    "        dict: A dictionary of class scores.\n",
    "    \"\"\"\n",
    "    class_scores = {}\n",
    "    present_classes = np.unique(remapped_mask)\n",
    "    target_classes = present_classes[present_classes > 0] # Classes 1, 2, 3\n",
    "\n",
    "    if target_classes.size == 0: return 0, {}\n",
    "\n",
    "    for class_val in target_classes:\n",
    "        mask_pixels = (remapped_mask == class_val)\n",
    "        if np.any(mask_pixels):\n",
    "             score = np.sum(heatmap[mask_pixels])\n",
    "             class_scores[class_val] = score\n",
    "        else:\n",
    "             class_scores[class_val] = 0\n",
    "\n",
    "    if not class_scores or all(s < 1e-9 for s in class_scores.values()):\n",
    "        selected_class = 0\n",
    "    else:\n",
    "        selected_class = max(class_scores, key=class_scores.get)\n",
    "\n",
    "    return selected_class, class_scores\n",
    "\n",
    "\n",
    "TRAIN_IMG_DIR   = \"astrain/color\"\n",
    "TRAIN_LBL_DIR   = \"astrain/label\"\n",
    "\n",
    "HEATMAP_SIGMA   = 3.0\n",
    "MAX_ATTEMPTS    = 1000\n",
    "\n",
    "PSTRAIN_BASE_DIR    = \"pstrain\"                # New base output directory\n",
    "PSTRAIN_IMG_DIR     = os.path.join(PSTRAIN_BASE_DIR, \"color\") # For COPIED original images\n",
    "PSTRAIN_HEATMAP_DIR = os.path.join(PSTRAIN_BASE_DIR, \"point_prompt\") # For heatmap IMAGES\n",
    "PSTRAIN_LABEL_DIR   = os.path.join(PSTRAIN_BASE_DIR, \"label\") # For final label masks\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "os.makedirs(PSTRAIN_IMG_DIR, exist_ok=True)\n",
    "os.makedirs(PSTRAIN_HEATMAP_DIR, exist_ok=True)\n",
    "os.makedirs(PSTRAIN_LABEL_DIR, exist_ok=True)\n",
    "print(f\"Reading original images from:   {os.path.abspath(TRAIN_IMG_DIR)}\")\n",
    "print(f\"Reading labels from:            {os.path.abspath(TRAIN_LBL_DIR)}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Saving copied images to:        {os.path.abspath(PSTRAIN_IMG_DIR)}\")\n",
    "print(f\"Saving heatmap images to:       {os.path.abspath(PSTRAIN_HEATMAP_DIR)}\")\n",
    "print(f\"Saving final label masks to:    {os.path.abspath(PSTRAIN_LABEL_DIR)}\")\n",
    "\n",
    "\n",
    "all_label_files = os.listdir(TRAIN_LBL_DIR)\n",
    "label_files = sorted([f for f in all_label_files if f.lower().endswith('.png') and not f.startswith('.')])\n",
    "\n",
    "\n",
    "# --- Loop through all found label files ---\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "error_count = 0\n",
    "img_not_found_count = 0\n",
    "\n",
    "total_files = len(label_files)\n",
    "print(f\"\\nStarting processing for {total_files} label files...\")\n",
    "\n",
    "for i, label_filename in enumerate(label_files):\n",
    "    img_name_base = os.path.splitext(label_filename)[0] # Get base name without extension\n",
    "    label_filepath = os.path.join(TRAIN_LBL_DIR, label_filename)\n",
    "\n",
    "    print(f\"\\nProcessing label {i+1}/{total_files}: {label_filename} (Base: {img_name_base})\")\n",
    "\n",
    "    # Find the corresponding original image file\n",
    "    original_img_path = None\n",
    "    original_img_ext = None\n",
    "    try:\n",
    "        found = False\n",
    "        for img_file in os.listdir(TRAIN_IMG_DIR):\n",
    "            if os.path.splitext(img_file)[0] == img_name_base:\n",
    "                original_img_path = os.path.join(TRAIN_IMG_DIR, img_file)\n",
    "                original_img_ext = os.path.splitext(img_file)[1] # Get extension (e.g., '.jpg')\n",
    "                print(f\"  Found corresponding image: {img_file}\")\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "                print(f\"  Skipping: Could not find corresponding image file for base name '{img_name_base}' in {TRAIN_IMG_DIR}\")\n",
    "                img_not_found_count += 1\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"!!! ERROR searching for image file for {label_filename}: {e}\")\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Load the label mask file \n",
    "        label_tensor_loaded = read_image(label_filepath)\n",
    "\n",
    "        # Handle channel issues (ensure single channel)\n",
    "        if label_tensor_loaded.shape[0] != 1:\n",
    "            if label_tensor_loaded.shape[0] == 3:\n",
    "                    label_tensor_loaded = label_tensor_loaded[0:1, :, :]\n",
    "                    print(f\"  Info: Label had 3 channels, took the first.\")\n",
    "            else:\n",
    "                print(f\"  Skipping: Label has unexpected shape {label_tensor_loaded.shape}, expected (1, H, W).\")\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "\n",
    "        # Apply the first remap (255 -> 3)\n",
    "        label_tensor_original = target_remap(label_tensor_loaded)\n",
    "\n",
    "        # Process the Loaded Mask ONCE per sample\n",
    "        label_squeezed = label_tensor_original.squeeze(0)\n",
    "        mask_post_remap1 = label_squeezed.numpy().astype(np.uint8)\n",
    "        mask_size = mask_post_remap1.shape\n",
    "\n",
    "        # Apply the SECOND remapping (Swap 3->0, Add 1) -> Final classes 1, 2, 3\n",
    "        mask_swapped = mask_post_remap1.copy()\n",
    "        mask_swapped[mask_post_remap1 == 3] = 0\n",
    "        remapped_mask_final = mask_swapped + 1\n",
    "        final_present_classes = np.unique(remapped_mask_final)\n",
    "        final_target_classes = final_present_classes[final_present_classes > 0]\n",
    "\n",
    "        # Check if finding two distinct classes is possible\n",
    "        if len(final_target_classes) < 2:\n",
    "            print(f\"  Skipping: Mask only contains {len(final_target_classes)} target class(es) {final_target_classes.tolist()} after remapping. Cannot select 2 distinct.\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # Loop to find TWO distinct class selections for this sample\n",
    "        selected_results = [] # List to store (selected_class, final_mask_array, heatmap_array)\n",
    "        attempts = 0\n",
    "        found_classes = set()\n",
    "\n",
    "        while len(selected_results) < 2 and attempts < MAX_ATTEMPTS:\n",
    "            attempts += 1\n",
    "            heatmap, center_coords = create_gaussian_heatmap(size=mask_size, sigma=HEATMAP_SIGMA)\n",
    "            current_selected_class, _ = select_dominant_class(heatmap, remapped_mask_final)\n",
    "\n",
    "            if current_selected_class > 0 and current_selected_class not in found_classes:\n",
    "                final_mask = np.zeros_like(remapped_mask_final, dtype=np.uint8)\n",
    "                final_mask[remapped_mask_final == current_selected_class] = current_selected_class\n",
    "                selected_results.append((current_selected_class, final_mask, heatmap))\n",
    "                found_classes.add(current_selected_class)\n",
    "                print(f\"    Attempt {attempts}: Found distinct class {current_selected_class} at {center_coords}\")\n",
    "\n",
    "\n",
    "        if len(selected_results) == 2:\n",
    "            print(f\"  Successfully found two distinct classes.\")\n",
    "            sel_cls_1, fin_msk_1, heatmap_1 = selected_results[0]\n",
    "            sel_cls_2, fin_msk_2, heatmap_2 = selected_results[1]\n",
    "\n",
    "            # --- Define final output filenames (consistent naming) ---\n",
    "            output_base_name_1 = f\"{img_name_base}_1\"\n",
    "            output_base_name_2 = f\"{img_name_base}_2\"\n",
    "\n",
    "            # Paths for triplet 1\n",
    "            output_img1_path = os.path.join(PSTRAIN_IMG_DIR, f\"{output_base_name_1}{original_img_ext}\")\n",
    "            output_heatmap1_path = os.path.join(PSTRAIN_HEATMAP_DIR, f\"{output_base_name_1}.png\")\n",
    "            output_label1_path = os.path.join(PSTRAIN_LABEL_DIR, f\"{output_base_name_1}.png\")\n",
    "\n",
    "            # Paths for triplet 2\n",
    "            output_img2_path = os.path.join(PSTRAIN_IMG_DIR, f\"{output_base_name_2}{original_img_ext}\")\n",
    "            output_heatmap2_path = os.path.join(PSTRAIN_HEATMAP_DIR, f\"{output_base_name_2}.png\")\n",
    "            output_label2_path = os.path.join(PSTRAIN_LABEL_DIR, f\"{output_base_name_2}.png\")\n",
    "\n",
    "\n",
    "            # Copy the original image twice\n",
    "            shutil.copy2(original_img_path, output_img1_path)\n",
    "            shutil.copy2(original_img_path, output_img2_path)\n",
    "            print(f\"    Copied original image to: {os.path.basename(output_img1_path)}\")\n",
    "            print(f\"    Copied original image to: {os.path.basename(output_img2_path)}\")\n",
    "\n",
    "            # Save Heatmaps as PNG Images (Scaled 0-255)\n",
    "            heatmap1_scaled = (heatmap_1 * 255).astype(np.uint8)\n",
    "            heatmap2_scaled = (heatmap_2 * 255).astype(np.uint8)\n",
    "            Image.fromarray(heatmap1_scaled, mode='L').save(output_heatmap1_path) # 'L' mode for grayscale\n",
    "            Image.fromarray(heatmap2_scaled, mode='L').save(output_heatmap2_path)\n",
    "            print(f\"    Saved Heatmap 1: {os.path.basename(output_heatmap1_path)}\")\n",
    "            print(f\"    Saved Heatmap 2: {os.path.basename(output_heatmap2_path)}\")\n",
    "\n",
    "\n",
    "            # Save Final Masks as PNG Images (already uint8)\n",
    "            Image.fromarray(fin_msk_1).save(output_label1_path)\n",
    "            Image.fromarray(fin_msk_2).save(output_label2_path)\n",
    "            print(f\"    Saved Label 1:   {os.path.basename(output_label1_path)}\")\n",
    "            print(f\"    Saved Label 2:   {os.path.basename(output_label2_path)}\")\n",
    "\n",
    "\n",
    "            processed_count += 1 # Count original files that yielded 2 outputs\n",
    "        else:\n",
    "            print(f\"  Skipping: Failed to find two distinct classes within {MAX_ATTEMPTS} attempts.\")\n",
    "            skipped_count += 1\n",
    "\n",
    "    except FileNotFoundError:\n",
    "            print(f\"!!! ERROR processing label file {label_filename}: File not found (unexpected).\")\n",
    "            error_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"!!! ERROR processing label file {label_filename}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        error_count += 1\n",
    "        # Continue to the next file\n",
    "\n",
    "\n",
    "# --- Final Summary ---\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"Processing Complete.\")\n",
    "print(f\"Output base directory:                          {os.path.abspath(PSTRAIN_BASE_DIR)}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total label files found:                        {total_files}\")\n",
    "print(f\"Successfully processed (2 triplets generated):  {processed_count}\")\n",
    "print(f\"Skipped (due to various reasons):               {skipped_count}\")\n",
    "print(f\"  - Skipped because original image not found:   {img_not_found_count}\")\n",
    "print(f\"  - Skipped (other reasons, e.g., too few classes): {skipped_count - img_not_found_count}\")\n",
    "print(f\"Errors during processing:                       {error_count}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total files created in '{os.path.basename(PSTRAIN_IMG_DIR)}':      {processed_count * 2}\")\n",
    "print(f\"Total files created in '{os.path.basename(PSTRAIN_HEATMAP_DIR)}':  {processed_count * 2}\")\n",
    "print(f\"Total files created in '{os.path.basename(PSTRAIN_LABEL_DIR)}':   {processed_count * 2}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Total time: {total_time:.2f} seconds\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
