{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.training import start\n",
    "from utils.MetricsHistory import MetricsHistory\n",
    "from unet.unet import unet\n",
    "from utils.weighted_loss import WeightedDiceCELoss\n",
    "from utils.utils import calculate_class_weights\n",
    "from utils.dataset import dataset, target_remap, diff_size_collate\n",
    "\n",
    "EVAL_IGNORE_INDEX = 3\n",
    "TRAIN_IGNORE_INDEX = None\n",
    "NUM_CLASSES = 4\n",
    "MODEL_NAME = \"tmp.pytorch\"\n",
    "MODEL_SAVE_DIR = \"tmp\"\n",
    "LOAD = False\n",
    "SAVE = False\n",
    "EPOCHS = 100\n",
    "WEIGHT_DECAY = 0.01\n",
    "TARGET_SIZE = 256\n",
    "\n",
    "# Determine the device to use (GPU if available, otherwise CPU)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "target_batch_size = 64\n",
    "batch_size = 2\n",
    "\n",
    "# Create datasets for training, validation, and testing\n",
    "training_data = dataset(\"datasets/astrain/color\", \"datasets/astrain/label\", target_transform=target_remap())\n",
    "val_data = dataset(\"datasets/Val/color\", \"datasets/Val/label\", target_transform=target_remap())\n",
    "test_data = dataset(\"datasets/Test/color\", \"datasets/Test/label\", target_transform=target_remap())\n",
    "\n",
    "# Create data loaders for training, validation, and testing\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=diff_size_collate)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=diff_size_collate)\n",
    "\n",
    "\n",
    "# Class Weights\n",
    "class_weight = Tensor([0.30711034803008996, 1.5412496145750956, 1.8445296893647247, 0.30711034803008996])\n",
    "class_weight = Tensor([0.2046795970925636, 1.0271954434416883, 1.2293222812780409, 1.5388026781877073])\n",
    "# class_weight = [1, 1, 1, 1]\n",
    "# class_weight = calculate_class_weights(training_data, 4, None, \"dataset\")\n",
    "class_weight = class_weight.to(device)\n",
    "class_weight = None\n",
    "\n",
    "# Calculate the number of accumulation steps\n",
    "accumulation_steps = target_batch_size // batch_size\n",
    "\n",
    "# Model\n",
    "model = unet(3, 4).to(device)\n",
    "\n",
    "# Losses\n",
    "train_loss_fn = WeightedDiceCELoss(ignore_index=TRAIN_IGNORE_INDEX, smooth_dice=1, class_weights=class_weight)\n",
    "val_loss_fn = WeightedDiceCELoss(ignore_index=EVAL_IGNORE_INDEX, class_weights=class_weight)\n",
    "\n",
    "train_loss_fn = nn.CrossEntropyLoss(weight=class_weight)\n",
    "val_loss_fn = nn.CrossEntropyLoss(weight=class_weight, ignore_index=EVAL_IGNORE_INDEX)\n",
    "\n",
    "train_loss_fn = nn.CrossEntropyLoss()\n",
    "val_loss_fn = nn.CrossEntropyLoss(ignore_index=EVAL_IGNORE_INDEX)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Scheduler\n",
    "scheduler = None\n",
    "\n",
    "# Metric History\n",
    "agg = MetricsHistory(NUM_CLASSES, EVAL_IGNORE_INDEX)\n",
    "\n",
    "# Training Pipiline\n",
    "start(\n",
    "    model_save_dir=MODEL_SAVE_DIR,\n",
    "    model_save_name=MODEL_NAME,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    accumulation_steps=accumulation_steps,\n",
    "    device=device,\n",
    "    train_loss_fn=train_loss_fn,\n",
    "    val_loss_fn=val_loss_fn,\n",
    "    scheduler=scheduler,\n",
    "    agg=agg,\n",
    "    load=LOAD,\n",
    "    save=SAVE,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    ignore_index=EVAL_IGNORE_INDEX,\n",
    "    target_size=TARGET_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
